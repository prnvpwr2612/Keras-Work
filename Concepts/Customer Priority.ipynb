{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, concatenate\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummy data\n",
    "titles = [\"Help with order\", \"Issue with payment\", \"Login problem\"]\n",
    "bodies = [\"I cannot find my order\", \"Payment method not working\", \"Cannot log in to my account\"]\n",
    "tags = [0, 1, 2]  # categorical tags\n",
    "\n",
    "# Tokenize the text inputs\n",
    "tokenizer = Tokenizer(num_words=100)\n",
    "tokenizer.fit_on_texts(titles + bodies)\n",
    "title_sequences = tokenizer.texts_to_sequences(titles)\n",
    "body_sequences = tokenizer.texts_to_sequences(bodies)\n",
    "\n",
    "# Pad the sequences\n",
    "title_data = pad_sequences(title_sequences, maxlen=5)\n",
    "body_data = pad_sequences(body_sequences, maxlen=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.88623702]\n",
      " [0.56034368]\n",
      " [0.8093288 ]]\n",
      "[0 1 1]\n",
      "[[1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# One-hot encode the tags\n",
    "tag_data = to_categorical(tags, num_classes=3)\n",
    "\n",
    "# Dummy outputs\n",
    "priority_scores = np.random.rand(len(titles), 1)\n",
    "departments = np.random.randint(0, 3, len(titles))\n",
    "department_data = to_categorical(departments, num_classes=3)\n",
    "\n",
    "print(priority_scores)\n",
    "print(departments)\n",
    "print(department_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ppawa\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Model inputs\n",
    "title_input = Input(shape=(5,), name='title_input')\n",
    "body_input = Input(shape=(20,), name='body_input')\n",
    "tag_input = Input(shape=(3,), name='tag_input')\n",
    "\n",
    "# Embedding and LSTM layers for text inputs\n",
    "embedding_layer = Embedding(input_dim=100, output_dim=10, input_length=5)\n",
    "title_embeddings = embedding_layer(title_input)\n",
    "title_lstm = LSTM(32)(title_embeddings)\n",
    "\n",
    "embedding_layer_body = Embedding(input_dim=100, output_dim=10, input_length=20)\n",
    "body_embeddings = embedding_layer_body(body_input)\n",
    "body_lstm = LSTM(32)(body_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate all inputs\n",
    "concat_layer = concatenate([title_lstm, body_lstm, tag_input])\n",
    "\n",
    "# Dense layers for output\n",
    "dense1 = Dense(64, activation='relu')(concat_layer)\n",
    "priority_output = Dense(1, \n",
    "                        activation='sigmoid', \n",
    "                        name='priority_output')(dense1)\n",
    "department_output = Dense(3, \n",
    "                          activation='softmax', \n",
    "                          name='department_output')(dense1)\n",
    "\n",
    "# Model definition\n",
    "model = Model(inputs=[title_input, body_input, tag_input], \n",
    "              outputs=[priority_output, department_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam', \n",
    "              loss={'priority_output': 'binary_crossentropy', \n",
    "                    'department_output': 'categorical_crossentropy'},\n",
    "              metrics={'priority_output': 'accuracy', \n",
    "                       'department_output': 'accuracy'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/45\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - department_output_accuracy: 1.0000 - loss: 0.5384 - priority_output_accuracy: 0.0000e+00 \n",
      "Epoch 2/45\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - department_output_accuracy: 1.0000 - loss: 0.5383 - priority_output_accuracy: 0.0000e+00 \n",
      "Epoch 3/45\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - department_output_accuracy: 1.0000 - loss: 0.5164 - priority_output_accuracy: 0.0000e+00 \n",
      "Epoch 4/45\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - department_output_accuracy: 1.0000 - loss: 0.5161 - priority_output_accuracy: 0.0000e+00 \n",
      "Epoch 5/45\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - department_output_accuracy: 1.0000 - loss: 0.5160 - priority_output_accuracy: 0.0000e+00 \n",
      "Epoch 6/45\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - department_output_accuracy: 1.0000 - loss: 0.5160 - priority_output_accuracy: 0.0000e+00 \n",
      "Epoch 7/45\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - department_output_accuracy: 1.0000 - loss: 0.4828 - priority_output_accuracy: 0.0000e+00\n",
      "Epoch 8/45\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - department_output_accuracy: 1.0000 - loss: 0.5160 - priority_output_accuracy: 0.0000e+00 \n",
      "Epoch 9/45\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - department_output_accuracy: 1.0000 - loss: 0.5156 - priority_output_accuracy: 0.0000e+00 \n",
      "Epoch 10/45\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385us/step - department_output_accuracy: 1.0000 - loss: 0.4823 - priority_output_accuracy: 0.0000e+00\n",
      "Epoch 11/45\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - department_output_accuracy: 1.0000 - loss: 0.5153 - priority_output_accuracy: 0.0000e+00 \n",
      "Epoch 12/45\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - department_output_accuracy: 1.0000 - loss: 0.4822 - priority_output_accuracy: 0.0000e+00 \n",
      "Epoch 13/45\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - department_output_accuracy: 1.0000 - loss: 0.4820 - priority_output_accuracy: 0.0000e+00 \n",
      "Epoch 14/45\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - department_output_accuracy: 1.0000 - loss: 0.4819 - priority_output_accuracy: 0.0000e+00 \n",
      "Epoch 15/45\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - department_output_accuracy: 1.0000 - loss: 0.5150 - priority_output_accuracy: 0.0000e+00 \n",
      "Epoch 16/45\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - department_output_accuracy: 1.0000 - loss: 0.5366 - priority_output_accuracy: 0.0000e+00 \n",
      "Epoch 17/45\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - department_output_accuracy: 1.0000 - loss: 0.5148 - priority_output_accuracy: 0.0000e+00 \n",
      "Epoch 18/45\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - department_output_accuracy: 1.0000 - loss: 0.4816 - priority_output_accuracy: 0.0000e+00 \n",
      "Epoch 19/45\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - department_output_accuracy: 1.0000 - loss: 0.4815 - priority_output_accuracy: 0.0000e+00 \n",
      "Epoch 20/45\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - department_output_accuracy: 1.0000 - loss: 0.5364 - priority_output_accuracy: 0.0000e+00 \n",
      "Epoch 21/45\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - department_output_accuracy: 1.0000 - loss: 0.4814 - priority_output_accuracy: 0.0000e+00 \n",
      "Epoch 22/45\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - department_output_accuracy: 1.0000 - loss: 0.4814 - priority_output_accuracy: 0.0000e+00 \n",
      "Epoch 23/45\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - department_output_accuracy: 1.0000 - loss: 0.4813 - priority_output_accuracy: 0.0000e+00 \n",
      "Epoch 24/45\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - department_output_accuracy: 1.0000 - loss: 0.4813 - priority_output_accuracy: 0.0000e+00 \n",
      "Epoch 25/45\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - department_output_accuracy: 1.0000 - loss: 0.5362 - priority_output_accuracy: 0.0000e+00 \n",
      "Epoch 26/45\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - department_output_accuracy: 1.0000 - loss: 0.5143 - priority_output_accuracy: 0.0000e+00 \n",
      "Epoch 27/45\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 906us/step - department_output_accuracy: 1.0000 - loss: 0.5361 - priority_output_accuracy: 0.0000e+00\n",
      "Epoch 28/45\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - department_output_accuracy: 1.0000 - loss: 0.5142 - priority_output_accuracy: 0.0000e+00 \n",
      "Epoch 29/45\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - department_output_accuracy: 1.0000 - loss: 0.5361 - priority_output_accuracy: 0.0000e+00\n",
      "Epoch 30/45\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - department_output_accuracy: 1.0000 - loss: 0.5360 - priority_output_accuracy: 0.0000e+00\n",
      "Epoch 31/45\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - department_output_accuracy: 1.0000 - loss: 0.4810 - priority_output_accuracy: 0.0000e+00 \n",
      "Epoch 32/45\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - department_output_accuracy: 1.0000 - loss: 0.5141 - priority_output_accuracy: 0.0000e+00 \n",
      "Epoch 33/45\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - department_output_accuracy: 1.0000 - loss: 0.4809 - priority_output_accuracy: 0.0000e+00 \n",
      "Epoch 34/45\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - department_output_accuracy: 1.0000 - loss: 0.5359 - priority_output_accuracy: 0.0000e+00 \n",
      "Epoch 35/45\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - department_output_accuracy: 1.0000 - loss: 0.5140 - priority_output_accuracy: 0.0000e+00 \n",
      "Epoch 36/45\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - department_output_accuracy: 1.0000 - loss: 0.5139 - priority_output_accuracy: 0.0000e+00 \n",
      "Epoch 37/45\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - department_output_accuracy: 1.0000 - loss: 0.5139 - priority_output_accuracy: 0.0000e+00 \n",
      "Epoch 38/45\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - department_output_accuracy: 1.0000 - loss: 0.4808 - priority_output_accuracy: 0.0000e+00 \n",
      "Epoch 39/45\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - department_output_accuracy: 1.0000 - loss: 0.5358 - priority_output_accuracy: 0.0000e+00 \n",
      "Epoch 40/45\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - department_output_accuracy: 1.0000 - loss: 0.5358 - priority_output_accuracy: 0.0000e+00 \n",
      "Epoch 41/45\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - department_output_accuracy: 1.0000 - loss: 0.5138 - priority_output_accuracy: 0.0000e+00 \n",
      "Epoch 42/45\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - department_output_accuracy: 1.0000 - loss: 0.4807 - priority_output_accuracy: 0.0000e+00 \n",
      "Epoch 43/45\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - department_output_accuracy: 1.0000 - loss: 0.5138 - priority_output_accuracy: 0.0000e+00 \n",
      "Epoch 44/45\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - department_output_accuracy: 1.0000 - loss: 0.4806 - priority_output_accuracy: 0.0000e+00 \n",
      "Epoch 45/45\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 823us/step - department_output_accuracy: 1.0000 - loss: 0.5357 - priority_output_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x192e11096d0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model on dummy data\n",
    "model.fit([title_data, body_data, tag_data], \n",
    "          [priority_scores, department_data], \n",
    "          epochs=45, \n",
    "          batch_size=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
